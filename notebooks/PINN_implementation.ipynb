{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With heavy help from https://github.com/benmoseley/harmonic-oscillator-pinn-workshop/blob/main/PINN_intro_workshop.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    #So bog basic it should tap for black mana\n",
    "    #DT That one's for you\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(8, 30)\n",
    "        self.linear2 = nn.Linear(30,30)\n",
    "        self.linear3 = nn.Linear(30,30)\n",
    "        self.linear4 = nn.Linear(30,8)\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.linear4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 9.81\n",
    "def derivatives(t, state):\n",
    "    L1, L2, m1, m2, theta1, z1, theta2, z2 = state\n",
    "    delta = theta2 - theta1\n",
    "\n",
    "    denominator1 = (m1 + m2) * L1 - m2 * L1 * np.cos(delta) ** 2\n",
    "    denominator2 = (L2 / L1) * denominator1\n",
    "\n",
    "    dtheta1_dt = z1\n",
    "    dz1_dt = (\n",
    "        (m2 * L1 * z1 ** 2 * np.sin(delta) * np.cos(delta)\n",
    "         + m2 * g * np.sin(theta2) * np.cos(delta)\n",
    "         + m2 * L2 * z2 ** 2 * np.sin(delta)\n",
    "         - (m1 + m2) * g * np.sin(theta1))\n",
    "        / denominator1\n",
    "    )\n",
    "    dtheta2_dt = z2\n",
    "    dz2_dt = (\n",
    "        (-m2 * L2 * z2 ** 2 * np.sin(delta) * np.cos(delta)\n",
    "         + (m1 + m2) * g * np.sin(theta1) * np.cos(delta)\n",
    "         - (m1 + m2) * L1 * z1 ** 2 * np.sin(delta)\n",
    "         - (m1 + m2) * g * np.sin(theta2))\n",
    "        / denominator2\n",
    "    )\n",
    "\n",
    "    return np.array([0,0,0,0,dtheta1_dt, dz1_dt, dtheta2_dt, dz2_dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data into a nice form\n",
    "with open('../data_folder/raw_data.json', 'r') as file:\n",
    "    raw_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gonna want inputs, a list of 8d vectors; and outputs, a list of 8d vectors that come immediately after inputs\n",
    "inputs = []\n",
    "outputs = []\n",
    "np.random.seed(522)\n",
    "ts_indices = np.random.choice(len(raw_data), replace=False, size=len(raw_data)//4)\n",
    "#Use a quarter of all time series generated 'cause there's a lot\n",
    "for i in ts_indices:\n",
    "    timeseries = raw_data[i]\n",
    "    n_tsteps = timeseries['num_tsteps']\n",
    "    #Also, use a quarter of all time steps\n",
    "    tstep_indices = np.random.choice(n_tsteps-1, replace=False, size=n_tsteps//4)\n",
    "    input_vecs = np.empty((len(tstep_indices), 8))\n",
    "    output_vecs = np.empty((len(tstep_indices), 8))\n",
    "    for j, k in enumerate(tstep_indices):\n",
    "        input_vecs[j, 4:] = np.array([timeseries['theta1'][k], timeseries['theta2'][k], timeseries['theta1prime'][k], timeseries['theta2prime'][k]])\n",
    "        output_vecs[j, 4:] = np.array([timeseries['theta1'][k+1], timeseries['theta2'][k+1], timeseries['theta1prime'][k+1], timeseries['theta2prime'][k+1]])\n",
    "    input_vecs[:, :4] = np.array([timeseries['length1'], timeseries['length2'], timeseries['mass1'], timeseries['mass2']])\n",
    "    output_vecs[:, :4] = np.array([timeseries['length1'], timeseries['length2'], timeseries['mass1'], timeseries['mass2']])\n",
    "    for j in range(len(input_vecs)):\n",
    "        inputs.append(list(input_vecs[j]))\n",
    "        outputs.append(list(output_vecs[j]))\n",
    "    \n",
    "test_indices = np.random.choice(len(inputs), replace=False, size = len(inputs)//5)\n",
    "remaining_indices = set(range(len(inputs))) - set(test_indices)\n",
    "val_indices = np.random.choice(list(remaining_indices), replace=False, size=len(inputs)//5)\n",
    "train_indices = list(set(range(len(inputs))) - set(test_indices) - set(val_indices))\n",
    "\n",
    "assert set(train_indices).union(set(test_indices)).union(set(val_indices)) == set(range(len(inputs)))\n",
    "assert len(set(train_indices).intersection(set(test_indices))) == 0\n",
    "assert len(set(train_indices).intersection(set(val_indices))) == 0\n",
    "assert len(set(test_indices).intersection(set(val_indices))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.tensor(np.array(inputs)[train_indices])\n",
    "train_y = torch.tensor(np.array(outputs)[train_indices])\n",
    "test_X = torch.tensor(np.array(inputs)[test_indices])\n",
    "test_y = torch.tensor(np.array(outputs)[test_indices])\n",
    "val_X = torch.tensor(np.array(inputs)[val_indices])\n",
    "val_y = torch.tensor(np.array(outputs)[val_indices])\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_dataset = data.TensorDataset(train_X, train_y)\n",
    "test_dataset = data.TensorDataset(test_X, test_y)\n",
    "val_dataset = data.TensorDataset(val_X, val_y)\n",
    "train_loader = data.DataLoader(train_dataset, shuffle=False, batch_size=batch_size) #Don't need to shuffle 'cause it's already randomly ordered\n",
    "test_loader = data.DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "val_loader = data.DataLoader(val_dataset, shuffle=False, batch_size=batch_size)\n",
    "#Make validation data too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 1/200\n",
    "pinn = FeedForward()\n",
    "optimizer = torch.optim.Adam(pinn.parameters(), lr=1e-4)\n",
    "num_epochs=10000\n",
    "lamb=1/2 #Test different values for this?\n",
    "for i in range(num_epochs):\n",
    "    pinn.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output_pred = pinn(X_batch)\n",
    "        derivs = (output_pred - X_batch) / \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #Gotta figure out the data-loading at some point...\n",
    "    #pinn() is supposed to approximate, as a function, the next timestep given the state of a system, and training data with consistent timesteps\n",
    "\n",
    "    #Gotta iterate over data loader somewhere in here\n",
    "    #derivs = (output_vector - input_data) / timestep\n",
    "    # physics_loss = (derivs - derivatives(input_data))**2 #Divide by N elns?\n",
    "    #data_loss = lamb*(true_output - output_vector)**2\n",
    "    #loss = physics_loss + data_loss\n",
    "    #loss.backward() etc\n",
    "    #optimizer.step()\n",
    "    #Get some validation or something to plot idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
